# U5 - Componentes de un procesador: Procesador

Def. previa: **Ciclo de reloj:** unidad b√°sica que mide la velocidad de una CPU. Durante cada ciclo, miles de millones de transistores dentro del procesador se abren y cierran. La frecuencia de reloj indica la frecuencia a la cual los transistores que lo conforman conmutan el√©ctricamente, es decir, abren y cierran el flujo de una corriente el√©ctrica.

## CISC (Complex Instruction Set Computer)
- Pocos registros de procesador (especializados)
- Set de Instrucciones amplio
- Muchas instrucciones para trabajar con memoria
- Microarquitectura en sofware/hardware compleja
- Instrucciones complejas (m√°s de un ciclo de reloj)
- Varios modos de direccionamiento, muchos tipos de datos, muchos formatos de instrucci√≥n (variables o h√≠bridos)
- Orientado al hardware, compiladores relativamente simples (tama√±o de c√≥digo peque√±o)
- Ejemplos: VAX, Intel x86 (hasta IA -32), Intel-64, IBM Mainframe

## RISC (Reduced Instruction Set Computer)
- Muchos registros de procesador de uso general
- Set de Instrucciones peque√±o
- Solo acceso a memoria a trav√©s de LOAD/STORE
- Microarquitectura en hardware simple
- Instrucciones simples (un ciclo de reloj)
- Pocos modos de direccionamiento, pocos tipos de datos, pocos formatos de instrucci√≥n (fijos)
- Orientado al software, compiladores relativamente complejos (tama√±o de c√≥digo largo)
- Ejemplos: SPARC, MIPS, ARM, Intel Itanium (IA-64)

## CISC vs RISC
Como los procesadores CISC tienen un conjunto de instrucciones m√°s complejo, pueden ejecutar programas de manera m√°s eficiente en t√©rminos de c√≥digo. En cambia, porque los procesadores RISC tienen un conjunto de instrucciones m√°s simple, tienden a ser m√°s r√°pidos y eficientes en t√©rminos de energ√≠a.

Mientras que los procesadores CISC pueden ser m√°s adecuados para sistemas con limitaciones de memoria y donde la compatibilidad con software existente es cr√≠tica, los procesadores RISC ofrecen ventajas en t√©rminos de velocidad, eficiencia energ√©tica y simplicidad de dise√±o, haci√©ndolos ideales para dispositivos m√≥viles y sistemas embebidos donde estos factores son prioritarios.

# Arquitectura de procesadores

## Ecuacion de *performance*
- MIPS = Millions of Instructions Per Second.
- An approximate measure of a computer's raw processing power

`MIPS rate = Frecuencia del reloj en MHz (f) * Instrucciones por ciclo (IPC)`

## Uniprocesadores (procesadores con un solo nucleo)
Un solo procesador central (CPU) que ejecuta todas las instrucciones y procesos.

Estos procesadores mejoraban ‚úîÔ∏è su rendimiento principalmente aumentando la velocidad del ciclo de reloj ‚è∞, es decir, incrementando la cantidad de ciclos de reloj que el CPU pod√≠a manejar.

üî¥ Una limitacion para seguir aumentando la velocidad es la generacion de calor üî• : trabajar üßë‚Äçüè≠ a mayor velocidad implica una generaci√≥n de calor m√°s alta debido a la mayor actividad de los transistores. Esto llev√≥ a que los primeros CPUs no necesitaran disipadores de calor, pero conforme se incremento la velocidad de los procesadores, se volvi√≥ necesario a√±adir disipadores de calor.

Hasta los 2000, la mejora continua de la velocidad de los procesadores seguia una tendencia exponencial üìà pero despues de ese punto se llego a un limite practico. En las ultimas dos decadas la frecuencia de los procesadores no ha experimentado un crecimiento tan significativo como en d√©cadas anteriores. A partir de aca los fabricantes se centraron en otras √°reas de mejora del rendimiento, como la eficiencia energ√©tica üîã, el dise√±o de n√∫cleos m√∫ltiples y la optimizaci√≥n del hardware üñ•Ô∏è y el software en general üò∏.

Hasta ese momento de limite se mejoraba la primera parte de la ecuacion de performance (la *frecuencia de reloj*)

## Tecnicas de procesamiento paralelo (Paralelismo)
Estas t√©cnicas permiten aumentar la eficiencia y reducir el tiempo necesario para completar una tarea, ya que las operaciones no se ejecutan secuencialmente sino en paralelo. 

Es un enfoque que ahora en vez de pedirle al CPU que ejecute mas instrucciones (para tener mayor *frecuencia de reloj**, mejorando la primera parte de la ecuacion), ahora se enfoca en implementar tecnicas para que el CPU ejecute mas instrucciones por ciclo de reloj (mejorando la segunda parte de la ecuacion)

Se pueden diferencias tecnicas con dos enfoques distintos:
- **A nivel instruccion:** pipelining, dual pipelining, superscalar, multithreading
- **A nivel procesador:** procesadores paralelos de datos, multiprocesadores, multicomputadoras

### Pipelining
- El CPU trata de ejecutar en paralelo mas de una instruccion de maquina, y con el pipelining lo logra solapando la ejecucion de las instrucciones: se permite que la ejecuci√≥n de una instrucci√≥n comience antes de que se complete la ejecuci√≥n de la instrucci√≥n anterior, y asi se logra reducir el tiempo total de una secuencia de instrucciones. **Se divide el ciclo de instruccion en etapas**
- Ejecucion de una instruccion por ciclo de reloj: cada etapa del pipeline est√° dise√±ada para completarse en un ciclo de reloj. Esto significa que, idealmente, una instrucci√≥n se ejecuta completamente en un solo ciclo de reloj.

![img](https://github.com/user-attachments/assets/e2838bab-6d76-4407-bbeb-1c62a72f3bf1) <br>
*A partir del t=5 se puede ver que hay cinco instrucciones siendo procesadas en paralelo*

#### Etapas 
En el hardware hay una unidad dedicada para cada etapa, cada unidad se va a llenar con la instruccion de maquina que este pasando por esa etapa. Las etapas son:
1. **Fetch:** leer la instrucci√≥n siguiente desde la memoria del programa y cargarla en el procesador. La direcci√≥n de la pr√≥xima instrucci√≥n a ejecutar se mantiene en el contador de programa (PC), que se actualiza despu√©s de cada captura.
2. **Decode**: la instrucci√≥n capturada se analiza para determinar qu√© acci√≥n debe realizar el procesador. Esto incluye identificar el c√≥digo de operaci√≥n (opcode) y los registros o ubicaciones de memoria involucrados.
3. **Operand Fetch**: el procesador recupera los operandos necesarios para la ejecuci√≥n de la instrucci√≥n. Los operandos pueden estar en registros dentro del procesador o en la memoria.
4. **Instruction Execution**: es donde se realiza la operaci√≥n especificada por la instrucci√≥n.
5. **Write Back**: los resultados de la ejecuci√≥n de la instrucci√≥n se escriben de vuelta en el lugar adecuado.

El pipelining permite que estas etapas se solapen en el tiempo; es decir, mientras una instrucci√≥n est√° siendo ejecutada, otra puede estar siendo decodificada, y una tercera puede estar siendo capturada.

#### Control de dependencia entre las instrucciones
Las instrucciones que entran al pipeline podrian utilizar datos no actualizados por una instruccion previa que no se termino de ejecutar. Para garantizar que las instrucciones se ejecuten correctamente en el pipeline y evitar problemas el pipelining requiere un control de dependencia entre las instrucciones.

Tipos de dependencias:
- Dependencias de datos: Ocurren cuando una instrucci√≥n depende de los resultados de otra. Por ejemplo, si una instrucci√≥n necesita el resultado de la instrucci√≥n anterior para ejecutarse correctamente.
- Dependencias de control: Se dan cuando el flujo de instrucciones depende del resultado de operaciones de control, como las bifurcaciones condicionales (if-else). Esto puede hacer que sea incierto qu√© instrucci√≥n debe ser cargada en el pipeline a continuaci√≥n.
- Dependencias de recursos: Suceden cuando dos o m√°s instrucciones necesitan el mismo recurso (como un registro o unidad de ejecuci√≥n) al mismo tiempo.

Para manejar estas dependencias y minimizar los retrasos (stalls) y las condiciones de peligro (hazards), se utilizan varias t√©cnicas mediante t√©cnicas de hardware o mediante optimizaciones realizadas por el compilador.

### Dual Pipelining
Se ejecutan dos instrucciones por ciclo de reloj. Se procesan de forma puramente paralela.

A considerar se puede mencionar que cada etapa ocupa un lugar fisico y que tambien habra mas generacion de calor.

Ejecutar dos instrucciones por ciclo en un procesador, complica a√∫n m√°s el procesarlas. Por eso el m√∫ltiple pipeline no ha llegado a mucho m√°s de cu√°druple pipeline, llevarlo a m√°s de esto eleva demasiado la complejidad.

![bjh](https://github.com/user-attachments/assets/7c2d9213-add3-4a0e-9a30-b6968c5a71bd)

### Superscalar (multiples unidades funcionales)
- Un procesador superscalar puede ejecutar mas de una instruccion por ciclo de reloj por tener multiples unidades funcionales, permitiendo que se atiendan mas de una instruccion a la vez.
- En el ejemplo se paraleliza en la etapa 4, la de ejecutar la instruccion, porque ahi se puede generar un cuello de botella: Sucede que la etapa 4 es mas lenta que la etapa 3, entonces en la 3 se tiene que quedar esperando.
- En la etapa 4 van a haber multiples unidades funcionales que pueden realizar en paralelo operaciones especificas por ejemplo, unidades aritm√©ticas y l√≥gicas, unidades de carga y almacenamiento, unidades para operaciones de punto flotante, etc.
- Esta tecnica se la conoce tambien como "N-way" o "N-issue", con un N entre 3 y 6 que indica cuando unidades funcionales van a estar disponibles en el dise√±o del hardware.
- Ej: linea de Intel Core

### Hardware multithreading
- El motivo es maximizar el uso del CPU intercambiando la ejecuci√≥n entre threads cuando uno est√° frenado por alguna causa.
- **Thread:** Contiene un PC (el RPI), un conjunto de registros y la pila (stack). Comparten un mismo address space. Se los conoce como ‚Äúlightweight processes‚Äù
- **Proceso:** Puede tener uno o m√°s threads, contiene un address space y un estado gestionado por el OS
- El cambio de contexto entre threads es ‚Äúliviano‚Äù (en un mismo ciclo de reloj) en comparaci√≥n con los procesos, que requieren del OS

Tecnicas para implementar el multithreading:
- **Fine-grained multithreading:** se intercambia el uso del procesador entre threads luego de la ejecuci√≥n de cada instrucci√≥n. Esto puede aumentar la utilizaci√≥n del procesador, pero tambi√©n puede introducir cierta complejidad y sobrecarga debido a la necesidad de administrar m√∫ltiples contextos de hilos. Ej. Procesadores Intel IA-32
- **Coarse-grained multithreading:** se intercambia el uso del procesador entre threads solo luego de alg√∫n evento significativo, como puede ser un page fault o un ‚Äúcache miss‚Äù. En este √∫ltimo caso se cambia la ejecuci√≥n a otro thread en vez de esperar el acceso m√°s lento a la memoria principal. Ej. Intel Itanium 2

### Procesadores paralelos de datos
Hay una sola unidad de control con multiples procesadores. Hay un solo CPU con varios nucleos (cores) que permiten paralelizar con unidades funcionales.

Metodos para realizar esto son:
- **SIMD [Single Instruction Multiple Data]**: Multiples procesadores ejecutan la misma secuencia de pasos sobre un conjunto diferente de datos. Ej: CPU

![ccc](https://github.com/user-attachments/assets/6047350f-6646-47b7-b626-8303dd7ba18b)

- Metodos **vectoriales**:
    - Similar a SIMD
    - Registro vectorial: conjunto de registros convencionales que se cargan desde memoria en una sola instruccion. Los registros trabajan como un bloque para recibir los elementos de un vector
    - Se opera por pipelining
    - Ej. Intel Core (SSE ‚Äì Streaming SIMD Extension)

![vnvj](https://github.com/user-attachments/assets/8ee56dfe-ac98-4ea4-88c1-44b23dcb0c72)

### Taxonomia de Flynn 
Dice que toda ejecucion de instrucciones en un uniprocesador caia en alguna de las siguientes clasificaciones:
- **SISD [Single Instruction Single Data]** (uniprocesadores) single data refiere a un unico conjunto de datos a la vez
- **SIMD [Single Instruction Multiple Data]**
- **MISD [Multiple Instruction Single Data]** (No comercial)
- **MIMD [Multiple Instruction Multiple Data]**

### Multiprocesadores
- M√∫ltiples CPUs que comparten memoria com√∫n
- Tiene una forma de ejecucion de instrucciones MIMD (Multiple Instruction Multiple data): multiples procesadores procesan multiples datos a la vez
- CPUs fuertemente acoplados porque no funcionan como computadoras independientes entre si.

#### Formas de implementar un multiprocesador
- Single bus y memoria compartida (centralizada) (UMA ‚Äì Uniform memory access) (SMP ‚Äì Symmetric multiprocessor). Ej. Intel Core i7
 
![ssss](https://github.com/user-attachments/assets/900b5af7-b675-4092-851a-06e6a2f29064)

- CPUs con memoria local y memoria compartida (NUMA ‚Äì non-uniform memory access), sirve porque no van a tener que competir todo el tiempo por el acceso a una memoria compartida, despues van a sincronizar la memoria local con la compartida. Ej. BBN Butterfly, SGI Origin 2000, Compaq AlphaServer GS320, Intel Itanium 2
 
![image](https://github.com/user-attachments/assets/100e4b87-99ad-4061-836a-6fabb6425d91)

### Multicomputadoras
- Computadores interconectados con memoria local (memoria distribuida)
- No hay memoria compartida. Los CPU son computadoras independientes
- CPUs ligeramente acoplados porque lo unico que comparten es informacion - Clusters
- MIMD (Multiple Instruction Multiple data)
- Intercambio de mensajes para la integracion entre las computadoras
- Topolog√≠as de grillas, √°rboles o anillos
- Ej. IBM Blue Gene/P. Supercomputadoras
